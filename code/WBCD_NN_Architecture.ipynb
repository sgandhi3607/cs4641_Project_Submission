{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WBCD Dataset Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrose\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import more Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 25\n",
    "\n",
    "\n",
    "columns = ['Radius','Texture','Perimeter','Area','Smoothness','Compactness',\n",
    "           'Concavity','Concave_Points','Symmetry','Fractal_Dimension',\n",
    "           'Malignant/Benign']\n",
    "\n",
    "# Read CSV file into pandas df\n",
    "df = pd.read_csv('../datasets/breast_cancer/breast-cancer-wisconsin.csv',\n",
    "                 delimiter=',', quotechar='\"', names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe without Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing dataframe head (without any preprocessing)....\n",
      "    Radius  Texture  Perimeter  Area  Smoothness  Compactness Concavity  \\\n",
      "0  1000025        5          1     1           1            2         1   \n",
      "1  1002945        5          4     4           5            7        10   \n",
      "2  1015425        3          1     1           1            2         2   \n",
      "3  1016277        6          8     8           1            3         4   \n",
      "4  1017023        4          1     1           3            2         1   \n",
      "5  1017122        8         10    10           8            7        10   \n",
      "6  1018099        1          1     1           1            2        10   \n",
      "7  1018561        2          1     2           1            2         1   \n",
      "8  1033078        2          1     1           1            2         1   \n",
      "9  1033078        4          2     1           1            2         1   \n",
      "\n",
      "   Concave_Points  Symmetry  Fractal_Dimension  Malignant/Benign  \n",
      "0               3         1                  1                 2  \n",
      "1               3         2                  1                 2  \n",
      "2               3         1                  1                 2  \n",
      "3               3         7                  1                 2  \n",
      "4               3         1                  1                 2  \n",
      "5               9         7                  1                 4  \n",
      "6               3         1                  1                 2  \n",
      "7               3         1                  1                 2  \n",
      "8               1         1                  5                 2  \n",
      "9               2         1                  1                 2  \n"
     ]
    }
   ],
   "source": [
    "print(\"Printing dataframe head (without any preprocessing)....\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/ipykernel_launcher.py:19: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "df = shuffle(df, random_state=RANDOM_SEED)\n",
    "\n",
    "# DROP USELESS ROWS AND COLUMNS\n",
    "df.dropna(inplace=True)\n",
    "cols = [0]\n",
    "# Drop ID column (it's not attribute or target)\n",
    "df.drop(df.columns[cols],axis=1,inplace=True)\n",
    "# Drop all data points with missing variables  (denoted by '?' entry)\n",
    "nostrings_row_list = [x.isdigit() for x in df.iloc[:,5]]\n",
    "df = df[nostrings_row_list]\n",
    "\n",
    "\n",
    "# Handle categorical data\n",
    "# df = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "# Split data into X and y vectors\n",
    "X = df.ix[:, df.columns != 'Malignant/Benign']\n",
    "y = df['Malignant/Benign']\n",
    "\n",
    "# Change 2 -> 0 (benign) and 4 -> 1 (malignant)\n",
    "y.replace(2, 0, inplace=True)\n",
    "y.replace(4, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check on Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: Printing out dataframe and shape after preprocessing... \n",
      "     Texture  Perimeter  Area  Smoothness  Compactness Concavity  \\\n",
      "437        4          1     1           1            2         1   \n",
      "511        5          1     1           1            2         1   \n",
      "215        8          7     8           7            5         5   \n",
      "684        1          1     1           1            2         1   \n",
      "302       10         10    10           7            9        10   \n",
      "341        1          1     1           1            2         1   \n",
      "608        5         10    10          10           10        10   \n",
      "366        6         10    10          10            8        10   \n",
      "205        5         10    10           9            6        10   \n",
      "270        8          4     7           1            3        10   \n",
      "\n",
      "     Concave_Points  Symmetry  Fractal_Dimension  Malignant/Benign  \n",
      "437               1         1                  1                 0  \n",
      "511               2         1                  1                 0  \n",
      "215               5        10                  2                 1  \n",
      "684               1         1                  1                 0  \n",
      "302               7        10                 10                 1  \n",
      "341               3         1                  1                 0  \n",
      "608              10         1                  1                 1  \n",
      "366               7        10                  7                 1  \n",
      "205               7        10                  5                 1  \n",
      "270               3         9                  2                 1  \n",
      "df.shape:  (683, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sanity Check: Printing out dataframe and shape after preprocessing... \")\n",
    "print(df.head(10))\n",
    "print(\"df.shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Split, Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/saksham/.local/lib/python3.5/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n",
      "/home/saksham/.local/lib/python3.5/site-packages/ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Split into 30%  training data, 70% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.30, random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "# Apply scaling. Large values of certain features undesireable for NN\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: Printing out X_train... \n",
      "[[ 0.21607913  0.26729122  0.89900862  1.44426357  2.63187492  0.94645923\n",
      "   1.85978038  2.25742091 -0.34434076]\n",
      " [-0.1425522   1.54175711  1.22554822  2.47980054  0.356122    1.76653327\n",
      "   1.45180653  0.66496637 -0.34434076]\n",
      " [ 2.00923577 -0.36994172 -0.4071498  -0.62681039 -0.55417916  0.67310122\n",
      "  -0.99603658 -0.60899726  0.20067541]\n",
      " [-1.21844619 -0.68855819 -0.7336894  -0.62681039 -1.00932974 -0.69368885\n",
      "  -0.99603658 -0.60899726 -0.34434076]]\n",
      "X_train.shape:  (478, 9)\n",
      "X_test.shape:  (205, 9)\n",
      "y_train.shape:  (478,)\n",
      "y_test.shape:  (205,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sanity Check: Printing out X_train... \")\n",
    "print(X_train[:4])\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different learning rates (Insert Algo, Sigmoid)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network object and fit object - attempt 1\n",
    "\n",
    "learning_rates = list()\n",
    "\n",
    "for x in range(0.001, 1, 0.005):\n",
    "    learning_rates.append(x)\n",
    "            \n",
    "\n",
    "# Create list to hold data on each trial\n",
    "data = []\n",
    "# Columns for df we'll create after loop \n",
    "cols = [\"Learning Rate\", \"training accuracy\", \"testing accuracy\", \"training MSE\", \"testing MSE\"]\n",
    "\n",
    "# COMMENCE TRAINING LOOP \n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "for lr in learning_rates: \n",
    "    print(\"Training lr: \", lr)\n",
    "\n",
    "    lr_nn_model_RHC_sigmoid = mlrose.NeuralNetwork(hidden_nodes = [10,10,10], activation = 'sigmoid', \n",
    "                                        algorithm = 'random_hill_climb', \n",
    "                                        max_iters = 1000, bias = True, is_classifier = True, \n",
    "                                        learning_rate = lr, early_stopping = True, \n",
    "                                        clip_max = 5, max_attempts = 100)\n",
    "\n",
    "    lr_nn_model_RHC_sigmoid.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction based on y_train and y_test \n",
    "    y_train_pred = lr_nn_model_RHC_sigmoid.predict(X_train)\n",
    "    y_test_pred = lr_nn_model_RHC_sigmoid.predict(X_test)\n",
    "    \n",
    "    # MSE Values \n",
    "    train_err = mean_squared_error(y_train,\n",
    "                        y_train_pred)\n",
    "    test_err = mean_squared_error(y_test,\n",
    "                        y_test_pred) \n",
    "\n",
    "    # Accuracy Values\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    x = architecture[0]\n",
    "    y = architecture[1]\n",
    "    z = architecture[2]\n",
    "    \n",
    "    # Append to data list \n",
    "    data.append([lr, y_train_accuracy, y_test_accuracy, train_err, test_err])\n",
    "    \n",
    "    \n",
    "# Store results from above into df \n",
    "\n",
    "learning_rate_result_df = pd.DataFrame(data, columns=cols)\n",
    "print(learning_rate_result_df)\n",
    "\n",
    "# Save to csv \n",
    "learning_rate_result_df.to_csv(\"RHC_Sigmoid_LearningRate_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Different Architectures (RHC, Sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network object and fit object - attempt 1\n",
    "\n",
    "hidden_node_architecture = list()\n",
    "\n",
    "for x in range(5, 40, 5):\n",
    "    for y in range(5, 40, 5):\n",
    "        for z in range(5, 40, 5):\n",
    "            hidden_node_architecture.append([x,y,z])\n",
    "            \n",
    "# hidden_node_architecture = [[5,5,5]]\n",
    "\n",
    "# Create list to hold data on each trial\n",
    "data = []\n",
    "# Columns for df we'll create after loop \n",
    "cols = [\"Nodes in each layer\", \"training accuracy\", \"testing accuracy\", \"training MSE\", \"testing MSE\"]\n",
    "\n",
    "# COMMENCE TRAINING LOOP \n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "for architecture in hidden_node_architecture: \n",
    "    print(\"Training architecture: \", architecture)\n",
    "\n",
    "    lr_nn_model_RHC_sigmoid = mlrose.NeuralNetwork(hidden_nodes = architecture, activation = 'sigmoid', \n",
    "                                        algorithm = 'random_hill_climb', \n",
    "                                        max_iters = 1000, bias = True, is_classifier = True, \n",
    "                                        learning_rate = 0.01, early_stopping = True, \n",
    "                                        clip_max = 5, max_attempts = 100)\n",
    "\n",
    "    lr_nn_model_RHC_sigmoid.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction based on y_train and y_test \n",
    "    y_train_pred = lr_nn_model_RHC_sigmoid.predict(X_train)\n",
    "    y_test_pred = lr_nn_model_RHC_sigmoid.predict(X_test)\n",
    "    \n",
    "    # MSE Values \n",
    "    train_err = mean_squared_error(y_train,\n",
    "                        y_train_pred)\n",
    "    test_err = mean_squared_error(y_test,\n",
    "                        y_test_pred) \n",
    "\n",
    "    # Accuracy Values\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    x = architecture[0]\n",
    "    y = architecture[1]\n",
    "    z = architecture[2]\n",
    "    \n",
    "    architecture_tup = (x,y,z)\n",
    "    \n",
    "    data.append([architecture_tup, y_train_accuracy, y_test_accuracy, train_err, test_err])\n",
    "    \n",
    "    \n",
    "# Store results from above into df \n",
    "\n",
    "result_df = pd.DataFrame(data, columns=cols)\n",
    "print(result_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"RHC_Sigmoid_Architecture_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort(key=lambda x: x[2], reverse=True)\n",
    "result_df_sorted = pd.DataFrame(data, columns=cols)\n",
    "result_df_sorted.to_csv(\"RHC_Sigmoid_Architecture_data(SORTED).csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Different Architectures (Gradient Descent, Sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize neural network object and fit object - attempt 1\n",
    "\n",
    "hidden_node_architecture = list()\n",
    "\n",
    "for x in range(5, 40, 5):\n",
    "    for y in range(5, 40, 5):\n",
    "        for z in range(5, 40, 5):\n",
    "            hidden_node_architecture.append([x,y,z])\n",
    "\n",
    "# Create list to hold data on each trial\n",
    "gd_data = []\n",
    "# Columns for df we'll create after loop \n",
    "cols = [\"Nodes in each layer\", \"training accuracy\", \"testing accuracy\", \"training MSE\", \"testing MSE\"]\n",
    "\n",
    "# COMMENCE TRAINING LOOP \n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "for architecture in hidden_node_architecture: \n",
    "    print(\"Training architecture: \", architecture)\n",
    "\n",
    "    lr_nn_model_RHC_sigmoid = mlrose.NeuralNetwork(hidden_nodes = architecture, activation = 'sigmoid', \n",
    "                                        algorithm = 'gradient_descent', \n",
    "                                        max_iters = 1000, bias = True, is_classifier = True, \n",
    "                                        learning_rate = 0.01, early_stopping = True, \n",
    "                                        clip_max = 5, max_attempts = 100)\n",
    "\n",
    "    lr_nn_model_RHC_sigmoid.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction based on y_train and y_test \n",
    "    y_train_pred = lr_nn_model_RHC_sigmoid.predict(X_train)\n",
    "    y_test_pred = lr_nn_model_RHC_sigmoid.predict(X_test)\n",
    "    \n",
    "    # MSE Values \n",
    "    train_err = mean_squared_error(y_train,\n",
    "                        y_train_pred)\n",
    "    test_err = mean_squared_error(y_test,\n",
    "                        y_test_pred) \n",
    "\n",
    "    # Accuracy Values\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    x = architecture[0]\n",
    "    y = architecture[1]\n",
    "    z = architecture[2]\n",
    "    \n",
    "    architecture_tup = (x,y,z)\n",
    "    \n",
    "    gd_data.append([architecture_tup, y_train_accuracy, y_test_accuracy, train_err, test_err])\n",
    "    \n",
    "    \n",
    "# Store results from above into df \n",
    "\n",
    "gradient_descent_result_df = pd.DataFrame(gd_data, columns=cols)\n",
    "print(gradient_descent_result_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_data.sort(key=lambda x: x[2], reverse=True)\n",
    "gd_result_df_sorted = pd.DataFrame(gd_data, columns=cols)\n",
    "gd_result_df_sorted.to_csv(\"WBCD_GD_Sigmoid_Architecture_data(SORTED)_VERSION2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Different Architectures (Simulated Annealing, Sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network object and fit object - attempt 1\n",
    "\n",
    "hidden_node_architecture = list()\n",
    "\n",
    "for x in range(5, 40, 5):\n",
    "    for y in range(5, 40, 5):\n",
    "        for z in range(5, 40, 5):\n",
    "            hidden_node_architecture.append([x,y,z])\n",
    "            \n",
    "# hidden_node_architecture = [[5,5,5]]\n",
    "\n",
    "# Create list to hold data on each trial\n",
    "sm_data = []\n",
    "# Columns for df we'll create after loop \n",
    "cols = [\"Nodes in each layer\", \"training accuracy\", \"testing accuracy\", \"training MSE\", \"testing MSE\"]\n",
    "\n",
    "# COMMENCE TRAINING LOOP \n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "for architecture in hidden_node_architecture: \n",
    "    print(\"Training architecture: \", architecture)\n",
    "\n",
    "    lr_nn_model_RHC_sigmoid = mlrose.NeuralNetwork(hidden_nodes = architecture, activation = 'sigmoid', \n",
    "                                        algorithm = 'simulated_annealing', \n",
    "                                        max_iters = 1000, bias = True, is_classifier = True, \n",
    "                                        learning_rate = 0.01, early_stopping = True, \n",
    "                                        clip_max = 5, max_attempts = 100)\n",
    "\n",
    "    lr_nn_model_RHC_sigmoid.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction based on y_train and y_test \n",
    "    y_train_pred = lr_nn_model_RHC_sigmoid.predict(X_train)\n",
    "    y_test_pred = lr_nn_model_RHC_sigmoid.predict(X_test)\n",
    "    \n",
    "    # MSE Values \n",
    "    train_err = mean_squared_error(y_train,\n",
    "                        y_train_pred)\n",
    "    test_err = mean_squared_error(y_test,\n",
    "                        y_test_pred) \n",
    "\n",
    "    # Accuracy Values\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    x = architecture[0]\n",
    "    y = architecture[1]\n",
    "    z = architecture[2]\n",
    "    \n",
    "    architecture_tup = (x,y,z)\n",
    "    \n",
    "    sm_data.append([architecture_tup, y_train_accuracy, y_test_accuracy, train_err, test_err])\n",
    "    \n",
    "    \n",
    "# Store results from above into df \n",
    "\n",
    "simulated_annealing_result_df = pd.DataFrame(sm_data, columns=cols)\n",
    "print(simulated_annealing_result_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_data.sort(key=lambda x: x[2], reverse=True)\n",
    "simulated_annealing_result_df = pd.DataFrame(sm_data, columns=cols)\n",
    "simulated_annealing_result_df.to_csv(\"WBCD_SM_Sigmoid_Architecture_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Different Architectures (Genetic Algorithms, Sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training architecture:  [5, 5, 5]\n",
      "Training architecture:  [5, 5, 10]\n",
      "Training architecture:  [5, 5, 15]\n",
      "Training architecture:  [5, 5, 20]\n",
      "Training architecture:  [5, 5, 25]\n",
      "Training architecture:  [5, 5, 30]\n",
      "Training architecture:  [5, 5, 35]\n",
      "Training architecture:  [5, 10, 5]\n",
      "Training architecture:  [5, 10, 10]\n",
      "Training architecture:  [5, 10, 15]\n",
      "Training architecture:  [5, 10, 20]\n",
      "Training architecture:  [5, 10, 25]\n",
      "Training architecture:  [5, 10, 30]\n",
      "Training architecture:  [5, 10, 35]\n",
      "Training architecture:  [5, 15, 5]\n",
      "Training architecture:  [5, 15, 10]\n",
      "Training architecture:  [5, 15, 15]\n",
      "Training architecture:  [5, 15, 20]\n",
      "Training architecture:  [5, 15, 25]\n",
      "Training architecture:  [5, 15, 30]\n",
      "Training architecture:  [5, 15, 35]\n",
      "Training architecture:  [5, 20, 5]\n",
      "Training architecture:  [5, 20, 10]\n",
      "Training architecture:  [5, 20, 15]\n",
      "Training architecture:  [5, 20, 20]\n",
      "Training architecture:  [5, 20, 25]\n",
      "Training architecture:  [5, 20, 30]\n",
      "Training architecture:  [5, 20, 35]\n",
      "Training architecture:  [5, 25, 5]\n",
      "Training architecture:  [5, 25, 10]\n",
      "Training architecture:  [5, 25, 15]\n",
      "Training architecture:  [5, 25, 20]\n",
      "Training architecture:  [5, 25, 25]\n",
      "Training architecture:  [5, 25, 30]\n",
      "Training architecture:  [5, 25, 35]\n",
      "Training architecture:  [5, 30, 5]\n",
      "Training architecture:  [5, 30, 10]\n",
      "Training architecture:  [5, 30, 15]\n",
      "Training architecture:  [5, 30, 20]\n",
      "Training architecture:  [5, 30, 25]\n",
      "Training architecture:  [5, 30, 30]\n",
      "Training architecture:  [5, 30, 35]\n",
      "Training architecture:  [5, 35, 5]\n",
      "Training architecture:  [5, 35, 10]\n",
      "Training architecture:  [5, 35, 15]\n",
      "Training architecture:  [5, 35, 20]\n",
      "Training architecture:  [5, 35, 25]\n",
      "Training architecture:  [5, 35, 30]\n",
      "Training architecture:  [5, 35, 35]\n",
      "Training architecture:  [10, 5, 5]\n",
      "Training architecture:  [10, 5, 10]\n",
      "Training architecture:  [10, 5, 15]\n",
      "Training architecture:  [10, 5, 20]\n",
      "Training architecture:  [10, 5, 25]\n",
      "Training architecture:  [10, 5, 30]\n",
      "Training architecture:  [10, 5, 35]\n",
      "Training architecture:  [10, 10, 5]\n",
      "Training architecture:  [10, 10, 10]\n",
      "Training architecture:  [10, 10, 15]\n",
      "Training architecture:  [10, 10, 20]\n",
      "Training architecture:  [10, 10, 25]\n",
      "Training architecture:  [10, 10, 30]\n",
      "Training architecture:  [10, 10, 35]\n",
      "Training architecture:  [10, 15, 5]\n",
      "Training architecture:  [10, 15, 10]\n",
      "Training architecture:  [10, 15, 15]\n",
      "Training architecture:  [10, 15, 20]\n",
      "Training architecture:  [10, 15, 25]\n",
      "Training architecture:  [10, 15, 30]\n",
      "Training architecture:  [10, 15, 35]\n",
      "Training architecture:  [10, 20, 5]\n",
      "Training architecture:  [10, 20, 10]\n",
      "Training architecture:  [10, 20, 15]\n",
      "Training architecture:  [10, 20, 20]\n",
      "Training architecture:  [10, 20, 25]\n",
      "Training architecture:  [10, 20, 30]\n",
      "Training architecture:  [10, 20, 35]\n",
      "Training architecture:  [10, 25, 5]\n",
      "Training architecture:  [10, 25, 10]\n",
      "Training architecture:  [10, 25, 15]\n",
      "Training architecture:  [10, 25, 20]\n",
      "Training architecture:  [10, 25, 25]\n",
      "Training architecture:  [10, 25, 30]\n",
      "Training architecture:  [10, 25, 35]\n",
      "Training architecture:  [10, 30, 5]\n",
      "Training architecture:  [10, 30, 10]\n",
      "Training architecture:  [10, 30, 15]\n",
      "Training architecture:  [10, 30, 20]\n",
      "Training architecture:  [10, 30, 25]\n",
      "Training architecture:  [10, 30, 30]\n",
      "Training architecture:  [10, 30, 35]\n",
      "Training architecture:  [10, 35, 5]\n",
      "Training architecture:  [10, 35, 10]\n",
      "Training architecture:  [10, 35, 15]\n",
      "Training architecture:  [10, 35, 20]\n",
      "Training architecture:  [10, 35, 25]\n",
      "Training architecture:  [10, 35, 30]\n",
      "Training architecture:  [10, 35, 35]\n",
      "Training architecture:  [15, 5, 5]\n",
      "Training architecture:  [15, 5, 10]\n",
      "Training architecture:  [15, 5, 15]\n",
      "Training architecture:  [15, 5, 20]\n",
      "Training architecture:  [15, 5, 25]\n",
      "Training architecture:  [15, 5, 30]\n",
      "Training architecture:  [15, 5, 35]\n",
      "Training architecture:  [15, 10, 5]\n",
      "Training architecture:  [15, 10, 10]\n",
      "Training architecture:  [15, 10, 15]\n",
      "Training architecture:  [15, 10, 20]\n",
      "Training architecture:  [15, 10, 25]\n",
      "Training architecture:  [15, 10, 30]\n",
      "Training architecture:  [15, 10, 35]\n",
      "Training architecture:  [15, 15, 5]\n",
      "Training architecture:  [15, 15, 10]\n",
      "Training architecture:  [15, 15, 15]\n",
      "Training architecture:  [15, 15, 20]\n",
      "Training architecture:  [15, 15, 25]\n",
      "Training architecture:  [15, 15, 30]\n",
      "Training architecture:  [15, 15, 35]\n",
      "Training architecture:  [15, 20, 5]\n",
      "Training architecture:  [15, 20, 10]\n",
      "Training architecture:  [15, 20, 15]\n",
      "Training architecture:  [15, 20, 20]\n",
      "Training architecture:  [15, 20, 25]\n",
      "Training architecture:  [15, 20, 30]\n",
      "Training architecture:  [15, 20, 35]\n",
      "Training architecture:  [15, 25, 5]\n",
      "Training architecture:  [15, 25, 10]\n",
      "Training architecture:  [15, 25, 15]\n",
      "Training architecture:  [15, 25, 20]\n",
      "Training architecture:  [15, 25, 25]\n",
      "Training architecture:  [15, 25, 30]\n",
      "Training architecture:  [15, 25, 35]\n",
      "Training architecture:  [15, 30, 5]\n",
      "Training architecture:  [15, 30, 10]\n",
      "Training architecture:  [15, 30, 15]\n",
      "Training architecture:  [15, 30, 20]\n",
      "Training architecture:  [15, 30, 25]\n",
      "Training architecture:  [15, 30, 30]\n",
      "Training architecture:  [15, 30, 35]\n",
      "Training architecture:  [15, 35, 5]\n",
      "Training architecture:  [15, 35, 10]\n",
      "Training architecture:  [15, 35, 15]\n",
      "Training architecture:  [15, 35, 20]\n",
      "Training architecture:  [15, 35, 25]\n",
      "Training architecture:  [15, 35, 30]\n",
      "Training architecture:  [15, 35, 35]\n",
      "Training architecture:  [20, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "# Initialize neural network object and fit object - attempt 1\n",
    "\n",
    "hidden_node_architecture = list()\n",
    "\n",
    "for x in range(5, 40, 5):\n",
    "    for y in range(5, 40, 5):\n",
    "        for z in range(5, 40, 5):\n",
    "            hidden_node_architecture.append([x,y,z])\n",
    "            \n",
    "# hidden_node_architecture = [[5,5,5]]\n",
    "\n",
    "# Create list to hold data on each trial\n",
    "ga_data = []\n",
    "# Columns for df we'll create after loop \n",
    "cols = [\"Nodes in each layer\", \"training accuracy\", \"testing accuracy\", \"training MSE\", \"testing MSE\"]\n",
    "\n",
    "# COMMENCE TRAINING LOOP \n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "for architecture in hidden_node_architecture: \n",
    "    print(\"Training architecture: \", architecture)\n",
    "\n",
    "    lr_nn_model_GA_sigmoid = mlrose.NeuralNetwork(hidden_nodes = architecture, activation = 'sigmoid', \n",
    "                                        algorithm = 'genetic_alg', \n",
    "                                        max_iters = 1000, bias = True, is_classifier = True, \n",
    "                                        learning_rate = 0.01, early_stopping = True, \n",
    "                                        pop_size=100,\n",
    "                                        clip_max = 5, max_attempts = 100)\n",
    "\n",
    "    lr_nn_model_GA_sigmoid.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction based on y_train and y_test \n",
    "    y_train_pred = lr_nn_model_GA_sigmoid.predict(X_train)\n",
    "    y_test_pred = lr_nn_model_GA_sigmoid.predict(X_test)\n",
    "    \n",
    "    # MSE Values \n",
    "    train_err = mean_squared_error(y_train,\n",
    "                        y_train_pred)\n",
    "    test_err = mean_squared_error(y_test,\n",
    "                        y_test_pred) \n",
    "\n",
    "    # Accuracy Values\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    x = architecture[0]\n",
    "    y = architecture[1]\n",
    "    z = architecture[2]\n",
    "    \n",
    "    architecture_tup = (x,y,z)\n",
    "    \n",
    "    ga_data.append([architecture_tup, y_train_accuracy, y_test_accuracy, train_err, test_err])\n",
    "    \n",
    "    \n",
    "# Store results from above into df \n",
    "\n",
    "genetic_alg_result_df = pd.DataFrame(ga_data, columns=cols)\n",
    "print(genetic_alg_result_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_data.sort(key=lambda x: x[2], reverse=True)\n",
    "genetic_alg_result_df = pd.DataFrame(ga_data, columns=cols)\n",
    "genetic_alg_result_df.to_csv(\"WBCD_GA_Sigmoid_Architecture_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Specific Architecture. Specify Everything "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training architecture:  [10, 10, 10]\n",
      "Training architecture:  [13, 13, 13]\n",
      "Training architecture:  [15, 15, 15]\n",
      "  Nodes in each layer  training accuracy  testing accuracy  training MSE  \\\n",
      "0        (10, 10, 10)           0.822176          0.839024      0.177824   \n",
      "1        (13, 13, 13)           0.165272          0.180488      0.834728   \n",
      "2        (15, 15, 15)           0.755230          0.717073      0.244770   \n",
      "\n",
      "   testing MSE  \n",
      "0     0.160976  \n",
      "1     0.819512  \n",
      "2     0.282927  \n"
     ]
    }
   ],
   "source": [
    "# Initialize neural network object and fit object - attempt 1\n",
    "\n",
    "hidden_node_architecture = list()\n",
    "\n",
    "# for x in range(5, 40, 5):\n",
    "#     for y in range(5, 40, 5):\n",
    "#         for z in range(5, 40, 5):\n",
    "#             hidden_node_architecture.append([x,y,z])\n",
    "            \n",
    "# hidden_node_architecture = [[10, 10, 10], [15,15,15], [20, 30, 30], [30, 30, 10], [30, 25, 20], \n",
    "#                             [5,20,20], [30,15,35]]\n",
    "\n",
    "hidden_node_architecture = [[10, 10, 10], [13, 13, 13], [15, 15, 15] ]\n",
    "# hidden_node_architecture = [[15, 15, 15] ]\n",
    "\n",
    "# Create list to hold data on each trial\n",
    "ga_data = []\n",
    "# Columns for df we'll create after loop \n",
    "cols = [\"Nodes in each layer\", \"training accuracy\", \"testing accuracy\", \"training MSE\", \"testing MSE\"]\n",
    "\n",
    "# COMMENCE TRAINING LOOP \n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "for architecture in hidden_node_architecture: \n",
    "    print(\"Training architecture: \", architecture)\n",
    "\n",
    "    lr_nn_model_GA_sigmoid = mlrose.NeuralNetwork(hidden_nodes = architecture, activation = 'tanh', \n",
    "                                        algorithm = 'simulated_annealing', \n",
    "                                        max_iters = 1000, bias = True, is_classifier = True, \n",
    "                                        learning_rate = 0.01, early_stopping = True, \n",
    "                                        pop_size=100,\n",
    "                                        clip_max = 5, max_attempts = 100)\n",
    "\n",
    "    lr_nn_model_GA_sigmoid.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction based on y_train and y_test \n",
    "    y_train_pred = lr_nn_model_GA_sigmoid.predict(X_train)\n",
    "    y_test_pred = lr_nn_model_GA_sigmoid.predict(X_test)\n",
    "    \n",
    "    # MSE Values \n",
    "    train_err = mean_squared_error(y_train,\n",
    "                        y_train_pred)\n",
    "    test_err = mean_squared_error(y_test,\n",
    "                        y_test_pred) \n",
    "\n",
    "    # Accuracy Values\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    x = architecture[0]\n",
    "    y = architecture[1]\n",
    "    z = architecture[2]\n",
    "    \n",
    "    architecture_tup = (x,y,z)\n",
    "    \n",
    "    ga_data.append([architecture_tup, y_train_accuracy, y_test_accuracy, train_err, test_err])\n",
    "    \n",
    "    \n",
    "# Store results from above into df \n",
    "\n",
    "genetic_alg_result_df = pd.DataFrame(ga_data, columns=cols)\n",
    "print(genetic_alg_result_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_data.sort(key=lambda x: x[2], reverse=True)\n",
    "genetic_alg_result_df = pd.DataFrame(ga_data, columns=cols)\n",
    "genetic_alg_result_df.to_csv(\"WBCD_RHC_TEST_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
