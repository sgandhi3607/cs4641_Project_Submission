{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WBCD Dataset Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrose\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import more Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 25\n",
    "\n",
    "\n",
    "columns = ['Radius','Texture','Perimeter','Area','Smoothness','Compactness',\n",
    "           'Concavity','Concave_Points','Symmetry','Fractal_Dimension',\n",
    "           'Malignant/Benign']\n",
    "\n",
    "# Read CSV file into pandas df\n",
    "df = pd.read_csv('../datasets/breast_cancer/breast-cancer-wisconsin.csv',\n",
    "                 delimiter=',', quotechar='\"', names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe without Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing dataframe head (without any preprocessing)....\n",
      "    Radius  Texture  Perimeter  Area  Smoothness  Compactness Concavity  \\\n",
      "0  1000025        5          1     1           1            2         1   \n",
      "1  1002945        5          4     4           5            7        10   \n",
      "2  1015425        3          1     1           1            2         2   \n",
      "3  1016277        6          8     8           1            3         4   \n",
      "4  1017023        4          1     1           3            2         1   \n",
      "5  1017122        8         10    10           8            7        10   \n",
      "6  1018099        1          1     1           1            2        10   \n",
      "7  1018561        2          1     2           1            2         1   \n",
      "8  1033078        2          1     1           1            2         1   \n",
      "9  1033078        4          2     1           1            2         1   \n",
      "\n",
      "   Concave_Points  Symmetry  Fractal_Dimension  Malignant/Benign  \n",
      "0               3         1                  1                 2  \n",
      "1               3         2                  1                 2  \n",
      "2               3         1                  1                 2  \n",
      "3               3         7                  1                 2  \n",
      "4               3         1                  1                 2  \n",
      "5               9         7                  1                 4  \n",
      "6               3         1                  1                 2  \n",
      "7               3         1                  1                 2  \n",
      "8               1         1                  5                 2  \n",
      "9               2         1                  1                 2  \n"
     ]
    }
   ],
   "source": [
    "print(\"Printing dataframe head (without any preprocessing)....\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/ipykernel_launcher.py:19: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "df = shuffle(df, random_state=RANDOM_SEED)\n",
    "\n",
    "# DROP USELESS ROWS AND COLUMNS\n",
    "df.dropna(inplace=True)\n",
    "cols = [0]\n",
    "# Drop ID column (it's not attribute or target)\n",
    "df.drop(df.columns[cols],axis=1,inplace=True)\n",
    "# Drop all data points with missing variables  (denoted by '?' entry)\n",
    "nostrings_row_list = [x.isdigit() for x in df.iloc[:,5]]\n",
    "df = df[nostrings_row_list]\n",
    "\n",
    "\n",
    "# Handle categorical data\n",
    "# df = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "# Split data into X and y vectors\n",
    "X = df.ix[:, df.columns != 'Malignant/Benign']\n",
    "y = df['Malignant/Benign']\n",
    "\n",
    "# Change 2 -> 0 (benign) and 4 -> 1 (malignant)\n",
    "y.replace(2, 0, inplace=True)\n",
    "y.replace(4, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check on Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: Printing out dataframe and shape after preprocessing... \n",
      "     Texture  Perimeter  Area  Smoothness  Compactness Concavity  \\\n",
      "437        4          1     1           1            2         1   \n",
      "511        5          1     1           1            2         1   \n",
      "215        8          7     8           7            5         5   \n",
      "684        1          1     1           1            2         1   \n",
      "302       10         10    10           7            9        10   \n",
      "341        1          1     1           1            2         1   \n",
      "608        5         10    10          10           10        10   \n",
      "366        6         10    10          10            8        10   \n",
      "205        5         10    10           9            6        10   \n",
      "270        8          4     7           1            3        10   \n",
      "\n",
      "     Concave_Points  Symmetry  Fractal_Dimension  Malignant/Benign  \n",
      "437               1         1                  1                 0  \n",
      "511               2         1                  1                 0  \n",
      "215               5        10                  2                 1  \n",
      "684               1         1                  1                 0  \n",
      "302               7        10                 10                 1  \n",
      "341               3         1                  1                 0  \n",
      "608              10         1                  1                 1  \n",
      "366               7        10                  7                 1  \n",
      "205               7        10                  5                 1  \n",
      "270               3         9                  2                 1  \n",
      "df.shape:  (683, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sanity Check: Printing out dataframe and shape after preprocessing... \")\n",
    "print(df.head(10))\n",
    "print(\"df.shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Split, Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saksham/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/saksham/.local/lib/python3.5/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n",
      "/home/saksham/.local/lib/python3.5/site-packages/ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Split into 30%  training data, 70% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.30, random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "# Apply scaling. Large values of certain features undesireable for NN\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: Printing out X_train... \n",
      "[[ 0.21607913  0.26729122  0.89900862  1.44426357  2.63187492  0.94645923\n",
      "   1.85978038  2.25742091 -0.34434076]\n",
      " [-0.1425522   1.54175711  1.22554822  2.47980054  0.356122    1.76653327\n",
      "   1.45180653  0.66496637 -0.34434076]\n",
      " [ 2.00923577 -0.36994172 -0.4071498  -0.62681039 -0.55417916  0.67310122\n",
      "  -0.99603658 -0.60899726  0.20067541]\n",
      " [-1.21844619 -0.68855819 -0.7336894  -0.62681039 -1.00932974 -0.69368885\n",
      "  -0.99603658 -0.60899726 -0.34434076]]\n",
      "X_train.shape:  (478, 9)\n",
      "X_test.shape:  (205, 9)\n",
      "y_train.shape:  (478,)\n",
      "y_test.shape:  (205,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sanity Check: Printing out X_train... \")\n",
    "print(X_train[:4])\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Annealing Hyperparameter Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NN with random restarts:  0\n",
      "Training NN with random restarts:  5\n",
      "Training NN with random restarts:  10\n",
      "Training NN with random restarts:  15\n",
      "Training NN with random restarts:  20\n",
      "Training NN with random restarts:  25\n",
      "Training NN with random restarts:  30\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "MAX_ITER = 3000\n",
    "max_iter = MAX_ITER \n",
    "\n",
    "hidden_node_architecture = [15, 15, 15]\n",
    "\n",
    "# Lists to hold values for x and y axes \n",
    "random_restart_list = list()\n",
    "testError = []\n",
    "trainError = []\n",
    "\n",
    "# Create list to hold data on each trial\n",
    "data = []\n",
    "# Columns for df we'll create after loop \n",
    "cols = [\"Max Iterations\", \"training accuracy\", \"testing accuracy\", \"training MSE\", \"testing MSE\"]\n",
    "\n",
    "# COMMENCE TRAINING LOOP \n",
    "for number_of_restarts in range(0, 51, 5) :\n",
    "    \n",
    "    print(\"Training NN with random restarts: \", number_of_restarts)\n",
    "    \n",
    "    nn_sigmoid = mlrose.NeuralNetwork(hidden_nodes = hidden_node_architecture, activation = 'sigmoid', \n",
    "                                        algorithm = 'simulated_annealing', \n",
    "                                        max_iters = max_iter, bias = True, is_classifier = True, \n",
    "                                        learning_rate = 0.01, early_stopping = True,\n",
    "                                        pop_size=100, restarts=number_of_restarts,\n",
    "                                        clip_max = 5, max_attempts = 100)\n",
    "\n",
    "    nn_sigmoid.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction based on y_train and y_test \n",
    "    y_train_pred = nn_sigmoid.predict(X_train)\n",
    "    y_test_pred = nn_sigmoid.predict(X_test)\n",
    "    \n",
    "    # MSE Values \n",
    "    train_err = mean_squared_error(y_train,\n",
    "                        y_train_pred)\n",
    "    test_err = mean_squared_error(y_test,\n",
    "                        y_test_pred) \n",
    "\n",
    "    # Accuracy Values\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    data.append([max_iter, y_train_accuracy, y_test_accuracy, train_err, test_err])\n",
    "    \n",
    "    \n",
    "    # Append data to lists\n",
    "    testError.append(test_err)\n",
    "    trainError.append(train_err)\n",
    "    random_restart_list.append(number_of_restarts)\n",
    "    \n",
    "    \n",
    "# Store results from above into df \n",
    "result_df = pd.DataFrame(data, columns=cols)\n",
    "print(result_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot it out (RHC Hyperparameter Testing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "title = \"WBCD NN Random Hill Climbing : Error x Number of Restarts - Learning Rate = .01, Hidden Layers = [15,15,15]\"\n",
    "plt.title('\\n'.join(wrap(title,60)))\n",
    "# plt.subplots_adjust(top=0.85)\n",
    "plt.plot(random_restart_list, testError, '-', label='Test Error')\n",
    "plt.plot(random_restart_list, trainError, '-', label='Train Error')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Restarts')\n",
    "plt.ylabel('Error')\n",
    "filename = 'WBCD_RHC_Hyperparameters_Restarts.png'\n",
    "plt.savefig(\"../plots/\" + filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
